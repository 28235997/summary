
## 硬件结构
冯诺依曼结构：
cpu，内存，输入设备，输出设备，总线
cpu：控制器，运算器，寄存器，程序计数器，高速缓存
总线：地址总线，控制总线，数据总线
输入输出设备：打印机，键盘，鼠标，显示器
内存：RAM

### cpu执行过程
1. 取指令，CPU读取程序计数器的值，这个值内存地址，然后由控制单元操作地址总线读取内存中的数据，通过地址总线传给CPU，CPU收到数据后，将指令放到指令寄存器里。
2. 指令译码，控制器将指令解析成不同的地址，操作数，操作信号
3. 通过电路将指令和数据传输到运算逻辑单元进行运算
4. 数据回写，回写到内存

### 缓存
l1 l2 l3 三级缓存，一级比一级慢，一级比一级大l3多个核心共享，l1 l2独占
写直达：直接写回内存
写回：在缓存没命中要从内存里取时原先的cache line里的数据如果是脏的，则写回内存，意思就是不直接写回，现标记为脏，需要替换时写回

#### 缓存一致性
并行计算时，多个cpu计算结果在各个cpu的缓存里，那么读取同一块数据就会出现缓存一致性问题
##### MESI协议
M： modified已修改，表示这个cache block中的数据已经被修改，但是还没有写回内存
E： exclusive独占，只有这个cpu的cache里有，可以随意读写，如果其他cpu也从内存中读取了这块数据，就会变成共享状态
S： shared共享，多个cpu都有这块数据
I： invalidated已失效，共享状态的数据要对其进行修改时，不能立即修改，要像其他cpu广播一个请求，标记为已失效，如果要写已失效的数据，其他cpu中有且是M状态，则先将其他cpu的cache里的数据写回内存，然后自己写，其他cpu的数据标记为I

### 中断
硬中断：主要处理耗时短，需要快速执行的
软中断：主要是延迟处理比较耗时的


## linux文件系统

文件系统的设计考虑点：
第一点，文件系统要有严格的组织形式，使得文件能够以块为单位进行存储。
`linux操作系统的文件是以块进行存储的，一般块为4K，所以文件被分散成一个一个的块`
第二点，文件系统中也要有索引区，用来方便查找一个文件分成的多个块都存放在了什么位置。
`既然是分散的，那就需要有索引用来找到他们，也就是inode，inode 里面有文件的读写权限 i_mode，属于哪个用户 i_uid，哪个组 i_gid，大小是多少 i_size_io，占用多少个块 i_blocks_io。“某个文件分成几块、每一块在哪里”，这些信息也在 inode 里面，保存在 i_block 里面。`
第三点，如果文件系统中有的文件是热点文件，近期经常被读取和写入，文件系统应该有缓存层。

第四点，文件应该用文件夹的形式组织起来，方便管理和查询。
第五点，Linux 内核要在自己的内存里面维护一套数据结构，来保存哪些文件被哪些进程打开和使用。

##### 一些汇编指令的含义
move a b :把b值赋给a,使a=b
call和ret :call调用子程序，子程序以ret结尾
jmp :无条件跳
int :中断指令
add a b : 加法,a=a+b
or :或运算
xor :异或运算
shl :算术左移
ahr :算术右移
push xxx :压xxx入栈
pop xxx: xxx出栈
inc: 加1
dec: 减1
sub a b : a=a-b
cmp: 减法比较，修改标志位


## linux 内存管理
用户的物理地址对进程不可见，操作系统给进程分配一个虚拟地址，所有进程看到的这个地址都是一样的，里面的内存都是从0开始编号

* 为什么要是用虚拟地址?
直接使用物理地址的缺陷：
1. 地址空间不隔离。所有程序直接访问物理地址，恶意程序很容易篡改，或者有些程序修改了其他程序的数据，就会造成其他程序崩溃
2. 内存使用率低。频繁的换入换出，如果C程序很大，当C运行时就需要将A,B都换出。
    `这个通过虚拟地址隔离的分页功能实现，把虚拟地址空间按页分割，常用的放到物理内存，不常用的放到磁盘，需要用时取出，可以实现内存共享，`
    那既然不是说是隔离的，为什么又说共享？
        同一块物理内存可以被多个程序共享，也就是多个程序的虚拟地址可以使用同一块物理地址，但是同一时刻是独占的，有操作系统进行调度。可以换出A的虚拟页，加载B的虚拟页，这两个页映射的物理地址是同一块
3. 程序运行地址不确定。程序每次运行时，我们都需要给他分配一块空闲区域，这块区域是不确定的，给程序编写造成许多麻烦。
4. 使用虚拟地址只要妥善处理好虚拟地址到物理地址的映射过程，就能达到隔离



### 分页
分页是把地址空间分成固定大小的页，虚拟地址空间和物理地址是同样的分法，都是4KB一页

### 装载执行步骤
* 可执行文件的装载，也就是程序的运行:
1. 建立虚拟地址空间和物理内存的映射，创建这样一个数据结构，而不是真正的映射上。当发生缺页中断的时候才映射(由伙伴系统进行映射)
2. 建立虚拟地址空间和可执行文件的映射，
3. 将cpu指令寄存器设置成可执行文件的入口，启动运行

### 页错误

当发现页面不存在时：
1. 如果内存中有空闲的物理页面，则分配一物理页帧r，然后转第4步，否则转第2步；
2. 选择某种页面置换算法，选择一个将被替换的物理页帧r，它所对应的逻辑页为q，如果该页在内存期间被修改过，则需把它写回到外存；
3. 将q所对应的页表项进行修改，把驻留位置0；
4. 查询可执行文件和虚拟页面的映射关系的数据结构，找到缺页所在的VMA，计算出偏移，将需要访问的页p装入到物理页面r中；
5. 修改p所对应的页表项的内容，把驻留位置1，把物理页帧号置为x；
6. 重新运行被中断的指令。

### 内核空间vs用户空间
内核空间地址是共享的，每个虚拟内存中的内核地址，其实关联的都是相同的物理内存

## 文件系统
一切皆文件
linux会为每个文件分配两个数据结构：
1. 索引节点(inode):记录文件的元信息，文件大小，访问权限，编号，在磁盘中的存储位置
2. 目录项(dentry):文件的名字，索引节点指针，目录层级关系

文件在磁盘中的存储方式：数据块每个4K，文件系统的基本操作单位是数据块
### 虚拟文件系统
文件系统种类繁多，为了提供统一的接口，引入了中间层，虚拟文件系统
文件系统需要挂载到某个目录才能正常使用，比如linux文件系统在启动时会挂载到根目录

文件的存储方式：连续和非连续，
* 非连续
索引方式存储，最高效，每个文件都有一个索引数据块，存放文件数据块的指针列表，要求文件头要包含执行索引数据块的指针，这样就可以知道索引数据块的位置，缺陷是索引带来的开销
当索引数据块特别大时，就索引加链表，用链表把索引数据块链起来

#### 软链接和硬链接
硬链接：多个目录项的索引节点(inode)指向同一个文件,就是多个文件的inode是一样的，所以只有当删除了所有的inode才算是删除
软连接：软连接也是一个文件，但是这个文件里记录的是链接的那个文件的路径，所以访问软连接实际上访问的是另一个文件

#### 阻塞与非阻塞IO，同步与异步IO
阻塞IO：用户执行read，线程会被阻塞，一直等到[内核把数据准备好]，并把[数据从内核缓冲区拷贝到应用缓冲区]，才会返回
非阻塞IO：在请求数据未准备好的情况下立即返回，此时应用程序不断轮询内核，知道数据准备好，内核将数据准备好，拷贝到应用缓冲区，返回

同步:从内核态拷贝到应用缓冲区的过程需要等待
异步非阻塞IO：内核准备数据和拷贝到应用缓冲区都不需要等待。

#### 零拷贝技术
不需要CPU进行数据的拷贝,提高性能，依靠DMA和SG-DMA，系统调用sendfile()代替read(),write()
使用了零拷贝技术的项目：
kafka
nginx，对应的配置 
http{
    sendfile on;
}

在大文件上，使用异步IO加直接IO，因为大文件不适合用缓冲区io，
nginx配置：
http{
    sendfile on;
    directio 1024m;
}

#### IO多路复用

最基本的socket模型：
server端：socket()->bind()->listen()->accept()->read()write()
client:socket()->connect()->read()write()

* 监听的 Socket 和真正⽤来传数据的 Socket 是两个
 
一个服务器理论上能建立多少个tcp连接？
依赖于服务器的内存，因为一个tcp连接需要维护一定的数据结构
* 多进程模型：fork一个进程来处理多个客户端连接，开销较大
* 多线程模型：pthread_create()创建一个线程来处理，但是多了照样扛不住

那么就有了[IO多路复用]技术, 我们熟悉的 select/poll/epoll 内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核中获取多个事件。
##### select/poll
把已连接的socket都放到一个文件描述符集合里，内核轮询，当有事件来时，标记为可读或者可写，在由用户态遍历，找到可用的socket，poll和select差不多都是使⽤「线性结构」存储进程关注的 Socket 集合，因此都
需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核
态之间拷⻉⽂件描述符集合，
##### epoll
epoll 通过两个⽅⾯，很好解决了 select/poll 的问题。
1. 采用红黑树来跟踪待检测的socket，
2. 事件驱动，利用回调函数，以时间通知的方式将有事件的socket加入到就绪socket队列中，当用户调用epoll_wait()时，只会返回有事件发生的文件描述符的个数，比之前用户遍历高效多了。

⽽且，epoll ⽀持[边缘触发]和[⽔平触发]的⽅式，⽽ select/poll 只⽀持⽔平触发，⼀般⽽⾔，边缘触发的⽅式会⽐⽔平触发的效率⾼。
边缘：只触发一次
水平：不断触发，只要有可read的数据就报告用户

#### 高性能网络模式：Reactor 和 Proactor


#### awk

* 统计nginx每天访问的ip数，每天一个ip多次算一次
awk '{print substr($4, 2,11)  " " $1}' access.log | sort | uniq | awk '{uv[$1]++;next}END{for (i in uv) print i,uv[i]}'

* 防火墙开启某个端口
iptables -I INPUT -ptcp --dport 3000 -j ACCEPT

* 字符串替换
sed -i 's/^\(字符串段1\).*\(字符串段2\)$/\1放入替换段1与段2之间的内容\2/' filename
